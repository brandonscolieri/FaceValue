{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Isabella_running_Divya_centering_with_std.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Sb1baeniKu0O","colab_type":"code","colab":{}},"source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GmMZr8VbK2O4","colab_type":"code","outputId":"e847bca6-37a8-4e10-d164-5dd55d2ecb80","executionInfo":{"status":"ok","timestamp":1557704922890,"user_tz":420,"elapsed":146878,"user":{"displayName":"Isabella Maceda","photoUrl":"","userId":"06888394138006873437"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a-5HzTYZK51G","colab_type":"code","outputId":"ccdce5ca-d70c-4aba-9d9e-50d35f1235b0","executionInfo":{"status":"ok","timestamp":1557704926167,"user_tz":420,"elapsed":150137,"user":{"displayName":"Isabella Maceda","photoUrl":"","userId":"06888394138006873437"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["import numpy as np\n","import tensorflow as tf\n","import tflearn\n","import pandas as pd\n","import sys\n","import os\n","import imageio\n","import matplotlib.pyplot as plt\n","import tflearn\n","from scipy.cluster.vq import whiten\n","\n","import PIL\n","from PIL import Image\n","\n","import IPython.display as display\n","# from IPython.display import display\n","\n","import pathlib\n","\n","\n","sys.path.insert(0, \"/content/gdrive/My Drive/182_final_project/\") # This enables us to import Python libraries in the folder.\n","\n","root_folder = \"/content/gdrive/My Drive/182_final_project/\"\n","\n","tf.reset_default_graph()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XsKq0R57K8Zp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"ce64b7dd-ceb7-470f-d8cc-9ded7ce43495","executionInfo":{"status":"ok","timestamp":1557705215786,"user_tz":420,"elapsed":439745,"user":{"displayName":"Isabella Maceda","photoUrl":"","userId":"06888394138006873437"}}},"source":["# Code to read csv file into colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive2 = GoogleDrive(gauth)\n","list_paths_work=[]"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |▎                               | 10kB 24.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 29.3MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 33.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 36.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 38.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 41.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 42.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 43.1MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 44.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 45.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 45.6MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 45.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 45.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 45.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 45.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 45.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 45.6MB/s \n","\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LDKwCLgHEwXk","colab_type":"code","colab":{}},"source":["first = np.load(root_folder + 'first_half_processed.npy', allow_pickle=True)\n","second = np.load(root_folder + 'second_half_processed_divya.npy', allow_pickle=True)\n","\n","first = [elem for elem in first if elem != None]\n","second =  [elem for elem in second if elem != None]\n","\n","full_data = first + second\n","\n","first = None\n","second = None\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRkARNBqAIun","colab_type":"code","colab":{}},"source":["def center(X): \n","  return (X - np.mean(X, axis=0))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qn9u2CvE5aWX","colab_type":"code","colab":{}},"source":["# def whiten(X, method='zca'):\n","#     \"\"\"\n","#     Whitens the input matrix X using specified whitening method.\n","#     Inputs:\n","#         X:      Input data matrix with data examples along the first dimension\n","#         method: Whitening method. Must be one of 'zca', 'zca_cor', 'pca',\n","#                 'pca_cor', or 'cholesky'.\n","#     \"\"\"\n","#     X = X.reshape((-1, np.prod(X.shape[1:])))\n","#     X_centered = X - np.mean(X, axis=0)\n","#     Sigma = np.dot(X_centered.T, X_centered) / X_centered.shape[0]\n","#     W = None\n","    \n","#     if method in ['zca', 'pca', 'cholesky']:\n","#         U, Lambda, _ = np.linalg.svd(Sigma)\n","#         if method == 'zca':\n","#             W = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(Lambda + 1e-5)), U.T))\n","#         elif method =='pca':\n","#             W = np.dot(np.diag(1.0 / np.sqrt(Lambda + 1e-5)), U.T)\n","#         elif method == 'cholesky':\n","#             W = np.linalg.cholesky(np.dot(U, np.dot(np.diag(1.0 / (Lambda + 1e-5)), U.T))).T\n","#     elif method in ['zca_cor', 'pca_cor']:\n","#         V_sqrt = np.diag(np.std(X, axis=0))\n","#         P = np.dot(np.dot(np.linalg.inv(V_sqrt), Sigma), np.linalg.inv(V_sqrt))\n","#         G, Theta, _ = np.linalg.svd(P)\n","#         if method == 'zca_cor':\n","#             W = np.dot(np.dot(G, np.dot(np.diag(1.0 / np.sqrt(Theta + 1e-5)), G.T)), V_sqrt)\n","#         elif method == 'pca_cor':\n","#             W = np.dot(np.dot(np.diag(1.0/np.sqrt(Theta + 1e-5)), G.T), V_sqrt)\n","#     else:\n","#         raise Exception('Whitening method not found.')\n","\n","#     return np.dot(X_centered, W.T)\n","\n","def zca_whitening_matrix(X):\n","    \"\"\"\n","    Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n","    INPUT:  X: [M x N] matrix.\n","        Rows: Variables\n","        Columns: Observations\n","    OUTPUT: ZCAMatrix: [M x M] matrix\n","    \"\"\"\n","    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n","    sigma = np.cov(X, rowvar=True) # [M x M]\n","    # Singular Value Decomposition. X = U * np.diag(S) * V\n","    U,S,V = np.linalg.svd(sigma)\n","        # U: [M x M] eigenvectors of sigma.\n","        # S: [M x 1] eigenvalues of sigma.\n","        # V: [M x M] transpose of U\n","    # Whitening constant: prevents division by zero\n","    epsilon = 1e-5\n","    # ZCA Whitening matrix: U * Lambda * U'\n","    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T)) # [M x M]\n","    return ZCAMatrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgutCFHqFJgj","colab_type":"code","colab":{}},"source":["# class_names = np.array(['Neutral', 'Happy', 'Sad', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt', None, 'Uncertain', 'No-Face'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mcaqC7QjFpeL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kptab_6ME64V","colab_type":"code","colab":{}},"source":["neutral = [elem for elem in full_data if int(elem[1]) == 0]\n","happy = [elem for elem in full_data if int(elem[1]) == 1]\n","sad = [elem for elem in full_data if int(elem[1]) == 2]\n","surprise = [elem for elem in full_data if int(elem[1]) == 3]\n","fear = [elem for elem in full_data if int(elem[1]) == 4]\n","disgust = [elem for elem in full_data if int(elem[1]) == 5]\n","anger = [elem for elem in full_data if int(elem[1]) == 6]\n","contempt = [elem for elem in full_data if int(elem[1]) == 7]\n","non = [elem for elem in full_data if int(elem[1]) == 8]\n","uncertain = [elem for elem in full_data if int(elem[1]) == 9]\n","noface = [elem for elem in full_data if int(elem[1]) == 10]\n","\n","emotions = [neutral, happy, sad, surprise, fear, disgust, anger, contempt, non, uncertain, noface]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ensnL942GcxH","colab_type":"code","colab":{}},"source":["import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Yg_1sNnE__d","colab_type":"code","colab":{}},"source":["training_data = []\n","for emotion in emotions:\n","  if len(emotion) <= 10000: \n","    training_data.extend(emotion)\n","  else:\n","    subsection = random.sample(emotion, 10000)\n","    training_data.extend(subsection)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwsxOuUYK--X","colab_type":"code","outputId":"166b7385-23af-4506-8531-a87133438f87","executionInfo":{"status":"ok","timestamp":1557705252290,"user_tz":420,"elapsed":476121,"user":{"displayName":"Isabella Maceda","photoUrl":"","userId":"06888394138006873437"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(training_data))\n","\n","train_images = [center(np.array(elem[0])).reshape((32, 32, 3)) for elem in training_data]\n","train_labels = [elem[1] for elem in training_data]"],"execution_count":12,"outputs":[{"output_type":"stream","text":["93417\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nyMwHJ3c6vvj","colab_type":"code","outputId":"e6259096-ff79-4939-9011-8fd6946beed3","executionInfo":{"status":"ok","timestamp":1557705252291,"user_tz":420,"elapsed":476105,"user":{"displayName":"Isabella Maceda","photoUrl":"","userId":"06888394138006873437"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_images[0].shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"wYSP8ijVLA65","colab_type":"code","colab":{}},"source":["# #reads in both halves of the training data and splits each element into \n","# #images, labels, and their file paths\n","\n","# first = np.load(root_folder + 'first_half_processed.npy', allow_pickle=True)\n","# second = np.load(root_folder + 'second_half_processed_divya.npy', allow_pickle=True)\n","\n","# first = [elem for elem in first if elem != None]\n","# second =  [elem for elem in second if elem != None]\n","\n","# full_data = first + second\n","\n","# first = None\n","# second = None\n","\n","# train_images = [elem[0] for elem in full_data]\n","# train_labels = [elem[1] for elem in full_data]\n","# # paths = [elem[2] for elem in full_data]\n","\n","# full_data = None\n","\n","# #converts the images into numerical form (32, 32, 3) tensors \n","# train_images = [np.array(elem) for elem in train_images]\n","\n","# #convert images to ints \n","# train_labels = [int(elem) for elem in train_labels]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8A9J1mjmbfn","colab_type":"code","colab":{}},"source":["#getting validation data\n","processed_validation = np.load(root_folder + 'processed_validation.npy', allow_pickle=True)\n","\n","processed_validation = [elem for elem in processed_validation if elem != None]\n","\n","val_images = [elem[0] for elem in processed_validation]\n","val_labels = [elem[1] for elem in processed_validation]\n","# val_paths = [elem[2] for elem in processed_validation]\n","\n","processed_validation = None\n","\n","\n","val_images= [center(np.array(elem)).reshape((32, 32,3)) for elem in val_images]\n","val_labels = [int(elem) for elem in val_labels]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Us-aat8vXuEl","colab_type":"code","colab":{}},"source":["# class_names = np.array(['Neutral', 'Happy', 'Sad', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt', None, 'Uncertain', 'No-Face'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHCoI-kq0Lbg","colab_type":"code","outputId":"5827aef1-87cd-4a04-ec67-7c05722024db","executionInfo":{"status":"ok","timestamp":1557705254011,"user_tz":420,"elapsed":477797,"user":{"displayName":"Isabella Maceda","photoUrl":"","userId":"06888394138006873437"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["'''Train a simple residual network on the CIFAR10 small images dataset.\n","It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n","(it's still underfitting at that point, though).\n","'''\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D, Add\n","import os\n","from keras.engine.topology import Layer\n","from scipy.cluster.vq import whiten\n","\n","# Define the residual block as a new layer\n","class Residual(Layer):\n","  def __init__(self, channels_in,kernel,**kwargs):\n","      super(Residual, self).__init__(**kwargs)\n","      self.channels_in = channels_in\n","      self.kernel = kernel\n","\n","  def call(self, x):\n","    # the residual block using Keras functional API\n","    first_layer = Activation(\"linear\", trainable=False)(x)\n","    x = Conv2D( self.channels_in, self.kernel, padding=\"same\")(first_layer)\n","    x = Activation(\"relu\")(x)\n","    x = Conv2D( self.channels_in, self.kernel, padding=\"same\")(x)\n","    residual = Add()([x, first_layer])\n","    x = Activation(\"relu\")(residual)\n","    return x\n","\n","  def compute_output_shape(self, input_shape):\n","    return input_shape\n","\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w5OUXO8MebGc","colab_type":"code","colab":{}},"source":["class LayerNormalization(Layer):\n","    def __init__(self, eps=1e-6, **kwargs):\n","        self.eps = eps\n","        super(LayerNormalization, self).__init__(**kwargs)\n","    def build(self, input_shape):\n","        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n","                                     initializer=Ones(), trainable=True)\n","        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n","                                    initializer=Zeros(), trainable=True)\n","        super(LayerNormalization, self).build(input_shape)\n","    def call(self, x):\n","        mean = K.mean(x, axis=-1, keepdims=True)\n","        std = K.std(x, axis=-1, keepdims=True)\n","        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n","    def compute_output_shape(self, input_shape):\n","        return input_shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"da3vPLopfSlQ","colab_type":"code","outputId":"d3305ae9-df3b-40cf-ce67-396b3a99b9e7","executionInfo":{"status":"error","timestamp":1557540120215,"user_tz":420,"elapsed":445042,"user":{"displayName":"Divya Periyakoil","photoUrl":"","userId":"03421379050660572113"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["batch_size = 128\n","num_classes = 11\n","epochs = 20\n","data_augmentation = True\n","# num_predictions = 20\n","save_dir = 'root_folder' + 'saved_models'\n","model_name = 'divabella2'\n","\n","# The data, split between train and test sets:\n","# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","\n","x_train = np.array(train_images)\n","y_train = np.array(train_labels)\n","\n","x_test = np.array(val_images)\n","y_test = np.array(val_labels)\n","\n","# train_images = None\n","# train_labels = None\n","# val_images = None\n","# val_labels = None\n","\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","\n","\n","model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n","model.add(Conv2D(32, 3, 3, border_mode='same', input_shape=(32,32,3), activation='relu'))\n","model.add(Conv2D(32, 3, 3, border_mode='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n","model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n","model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n","model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","model.add(Activation('relu'))\n","model.add(Residual(256,(3,3)))\n","model.add(Residual(256,(3,3)))\n","model.add(Residual(256,(3,3)))\n","model.add(Residual(256,(3,3)))\n","model.add(Residual(256,(3,3)))\n","\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","# model.add(BatchNormalization()) #we are adding this in just to see iteration 2\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=5e-2, decay=1e-7) # tried (0.001, 1e-6)(0.0001, 1e-7)(0.00001, 1e-7)(0.001, 1e-5) #original (0.0001, 1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        validation_data=(x_test, y_test),\n","                        workers=4, steps_per_epoch = 5000)\n","\n","  # Save model and weights\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","model_path = root_folder + 'saved_models/' + model_name\n","model.save(model_path)\n","print('Saved trained model at %s ' % model_path)\n","\n","# Score trained model.\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (93417, 32, 32, 3)\n","93417 train samples\n","5256 test samples\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Using real-time data augmentation.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/20\n","5000/5000 [==============================] - 335s 67ms/step - loss: 14.3798 - acc: 0.1077 - val_loss: 14.6216 - val_acc: 0.0928\n","Epoch 2/20\n","5000/5000 [==============================] - 321s 64ms/step - loss: 14.3920 - acc: 0.1071 - val_loss: 14.6216 - val_acc: 0.0928\n","Epoch 3/20\n","5000/5000 [==============================] - 322s 64ms/step - loss: 14.3891 - acc: 0.1073 - val_loss: 14.6216 - val_acc: 0.0928\n","Epoch 4/20\n","5000/5000 [==============================] - 323s 65ms/step - loss: 14.3881 - acc: 0.1073 - val_loss: 14.6216 - val_acc: 0.0928\n","Epoch 5/20\n","5000/5000 [==============================] - 320s 64ms/step - loss: 14.3930 - acc: 0.1070 - val_loss: 14.6216 - val_acc: 0.0928\n","Epoch 6/20\n","5000/5000 [==============================] - 320s 64ms/step - loss: 14.3928 - acc: 0.1070 - val_loss: 14.6216 - val_acc: 0.0928\n","Epoch 7/20\n","5000/5000 [==============================] - 323s 65ms/step - loss: 14.3967 - acc: 0.1068 - val_loss: 14.6216 - val_acc: 0.0928\n","Epoch 8/20\n","5000/5000 [==============================] - 323s 65ms/step - loss: 14.3922 - acc: 0.1071 - val_loss: 14.6216 - val_acc: 0.0928\n","Epoch 9/20\n","5000/5000 [==============================] - 321s 64ms/step - loss: 14.3932 - acc: 0.1070 - val_loss: 14.6216 - val_acc: 0.0928\n","Epoch 10/20\n","3162/5000 [=================>............] - ETA: 1:58 - loss: 14.3927 - acc: 0.1070"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nR2eHA-rgivC","colab_type":"code","colab":{}},"source":["model_path = root_folder + 'saved_models/' + 'best_model'\n","model.save(model_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"keCjQH_bh57W","colab_type":"code","colab":{}},"source":["# model = Sequential()\n","\n","# model.add(Conv2D(32, 3, 3, border_mode='same', input_shape=(32,32,3), activation='relu'))\n","# model.add(Conv2D(32, 3, 3, border_mode='same', activation='relu'))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n","# model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","# model.add(Conv2D(32, 3, 3, border_mode='same', activation='relu'))\n","\n","# model.add()\n","# model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n","# model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n","# model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# model.add(Flatten())\n","# model.add(Dense(256, activation='relu'))\n","# model.add(Dropout(0.5))\n","\n","# model.add(Dense(256, activation='relu'))\n","# model.add(Dropout(0.5))\n","\n","# model.add(Dense(11))\n","# model.add(Activation('softmax'))\n","    \n","# model.compile(loss='categorical_crossentropy',\n","#             optimizer=RMSprop(lr=0.0001),\n","#             metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8A3hmipVuafi","colab_type":"code","colab":{}},"source":["# model.fit(np.array(train_images), train_labels, epochs=100, batch_size=5000, validation_data=(np.array(val_images),val_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eg0xbYo2AQ-l","colab_type":"code","colab":{}},"source":["# model.predict_classes(np.array(val_images))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JAdVFWYZgnOJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}