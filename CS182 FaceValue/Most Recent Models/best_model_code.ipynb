{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Divya_model_DO_NOT_TOUCH.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Sb1baeniKu0O","colab_type":"code","outputId":"5824aa84-60e8-4391-ddfc-41f06b655389","executionInfo":{"status":"ok","timestamp":1557631213283,"user_tz":420,"elapsed":1615,"user":{"displayName":"Divya Periyakoil","photoUrl":"","userId":"03421379050660572113"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GmMZr8VbK2O4","colab_type":"code","outputId":"dd09c333-38ef-4309-f369-2e79427530c8","executionInfo":{"status":"ok","timestamp":1557631213285,"user_tz":420,"elapsed":1595,"user":{"displayName":"Divya Periyakoil","photoUrl":"","userId":"03421379050660572113"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a-5HzTYZK51G","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import tflearn\n","import pandas as pd\n","import sys\n","import os\n","import imageio\n","import matplotlib.pyplot as plt\n","import tflearn\n","\n","import PIL\n","from PIL import Image\n","\n","import IPython.display as display\n","# from IPython.display import display\n","\n","import pathlib\n","\n","\n","sys.path.insert(0, \"/content/gdrive/My Drive/182_final_project/\") # This enables us to import Python libraries in the folder.\n","\n","root_folder = \"/content/gdrive/My Drive/182_final_project/\"\n","\n","tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XsKq0R57K8Zp","colab_type":"code","colab":{}},"source":["# Code to read csv file into colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive2 = GoogleDrive(gauth)\n","list_paths_work=[]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LDKwCLgHEwXk","colab_type":"code","colab":{}},"source":["first = np.load(root_folder + 'first_half_processed.npy', allow_pickle=True)\n","second = np.load(root_folder + 'second_half_processed_divya.npy', allow_pickle=True)\n","\n","first = [elem for elem in first if elem != None]\n","second =  [elem for elem in second if elem != None]\n","\n","full_data = first + second\n","\n","first = None\n","second = None\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRkARNBqAIun","colab_type":"code","colab":{}},"source":["def center(X): \n","  return (X - np.mean(X, axis=0))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qn9u2CvE5aWX","colab_type":"code","colab":{}},"source":["# def whiten(X, method='zca'):\n","#     \"\"\"\n","#     Whitens the input matrix X using specified whitening method.\n","#     Inputs:\n","#         X:      Input data matrix with data examples along the first dimension\n","#         method: Whitening method. Must be one of 'zca', 'zca_cor', 'pca',\n","#                 'pca_cor', or 'cholesky'.\n","#     \"\"\"\n","#     X = X.reshape((-1, np.prod(X.shape[1:])))\n","#     X_centered = X - np.mean(X, axis=0)\n","#     Sigma = np.dot(X_centered.T, X_centered) / X_centered.shape[0]\n","#     W = None\n","    \n","#     if method in ['zca', 'pca', 'cholesky']:\n","#         U, Lambda, _ = np.linalg.svd(Sigma)\n","#         if method == 'zca':\n","#             W = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(Lambda + 1e-5)), U.T))\n","#         elif method =='pca':\n","#             W = np.dot(np.diag(1.0 / np.sqrt(Lambda + 1e-5)), U.T)\n","#         elif method == 'cholesky':\n","#             W = np.linalg.cholesky(np.dot(U, np.dot(np.diag(1.0 / (Lambda + 1e-5)), U.T))).T\n","#     elif method in ['zca_cor', 'pca_cor']:\n","#         V_sqrt = np.diag(np.std(X, axis=0))\n","#         P = np.dot(np.dot(np.linalg.inv(V_sqrt), Sigma), np.linalg.inv(V_sqrt))\n","#         G, Theta, _ = np.linalg.svd(P)\n","#         if method == 'zca_cor':\n","#             W = np.dot(np.dot(G, np.dot(np.diag(1.0 / np.sqrt(Theta + 1e-5)), G.T)), V_sqrt)\n","#         elif method == 'pca_cor':\n","#             W = np.dot(np.dot(np.diag(1.0/np.sqrt(Theta + 1e-5)), G.T), V_sqrt)\n","#     else:\n","#         raise Exception('Whitening method not found.')\n","\n","#     return np.dot(X_centered, W.T)\n","\n","def zca_whitening_matrix(X):\n","    \"\"\"\n","    Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n","    INPUT:  X: [M x N] matrix.\n","        Rows: Variables\n","        Columns: Observations\n","    OUTPUT: ZCAMatrix: [M x M] matrix\n","    \"\"\"\n","    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n","    sigma = np.cov(X, rowvar=True) # [M x M]\n","    # Singular Value Decomposition. X = U * np.diag(S) * V\n","    U,S,V = np.linalg.svd(sigma)\n","        # U: [M x M] eigenvectors of sigma.\n","        # S: [M x 1] eigenvalues of sigma.\n","        # V: [M x M] transpose of U\n","    # Whitening constant: prevents division by zero\n","    epsilon = 1e-5\n","    # ZCA Whitening matrix: U * Lambda * U'\n","    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T)) # [M x M]\n","    return ZCAMatrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgutCFHqFJgj","colab_type":"code","colab":{}},"source":["# class_names = np.array(['Neutral', 'Happy', 'Sad', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt', None, 'Uncertain', 'No-Face'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mcaqC7QjFpeL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kptab_6ME64V","colab_type":"code","colab":{}},"source":["neutral = [elem for elem in full_data if int(elem[1]) == 0]\n","happy = [elem for elem in full_data if int(elem[1]) == 1]\n","sad = [elem for elem in full_data if int(elem[1]) == 2]\n","surprise = [elem for elem in full_data if int(elem[1]) == 3]\n","fear = [elem for elem in full_data if int(elem[1]) == 4]\n","disgust = [elem for elem in full_data if int(elem[1]) == 5]\n","anger = [elem for elem in full_data if int(elem[1]) == 6]\n","contempt = [elem for elem in full_data if int(elem[1]) == 7]\n","non = [elem for elem in full_data if int(elem[1]) == 8]\n","uncertain = [elem for elem in full_data if int(elem[1]) == 9]\n","noface = [elem for elem in full_data if int(elem[1]) == 10]\n","\n","emotions = [neutral, happy, sad, surprise, fear, disgust, anger, contempt, non, uncertain, noface]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ensnL942GcxH","colab_type":"code","colab":{}},"source":["import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Yg_1sNnE__d","colab_type":"code","colab":{}},"source":["training_data = []\n","for emotion in emotions:\n","  if len(emotion) <= 10000: \n","    training_data.extend(emotion)\n","  else:\n","    subsection = random.sample(emotion, 10000)\n","    training_data.extend(subsection)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwsxOuUYK--X","colab_type":"code","outputId":"158057df-4c3e-4a0a-c7cf-4e1e4ee599a5","executionInfo":{"status":"ok","timestamp":1557631213302,"user_tz":420,"elapsed":1423,"user":{"displayName":"Divya Periyakoil","photoUrl":"","userId":"03421379050660572113"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(training_data))\n","\n","train_images = [center(np.array(elem[0])).reshape((32, 32, 3)) for elem in training_data]\n","train_labels = [elem[1] for elem in training_data]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["93417\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nyMwHJ3c6vvj","colab_type":"code","outputId":"93928a03-7fd3-4fb6-e86b-67572de843fa","executionInfo":{"status":"ok","timestamp":1557631213303,"user_tz":420,"elapsed":1408,"user":{"displayName":"Divya Periyakoil","photoUrl":"","userId":"03421379050660572113"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_images[0].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"wYSP8ijVLA65","colab_type":"code","colab":{}},"source":["# #reads in both halves of the training data and splits each element into \n","# #images, labels, and their file paths\n","\n","# first = np.load(root_folder + 'first_half_processed.npy', allow_pickle=True)\n","# second = np.load(root_folder + 'second_half_processed_divya.npy', allow_pickle=True)\n","\n","# first = [elem for elem in first if elem != None]\n","# second =  [elem for elem in second if elem != None]\n","\n","# full_data = first + second\n","\n","# first = None\n","# second = None\n","\n","# train_images = [elem[0] for elem in full_data]\n","# train_labels = [elem[1] for elem in full_data]\n","# # paths = [elem[2] for elem in full_data]\n","\n","# full_data = None\n","\n","# #converts the images into numerical form (32, 32, 3) tensors \n","# train_images = [np.array(elem) for elem in train_images]\n","\n","# #convert images to ints \n","# train_labels = [int(elem) for elem in train_labels]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8A9J1mjmbfn","colab_type":"code","colab":{}},"source":["#getting validation data\n","processed_validation = np.load(root_folder + 'processed_validation.npy', allow_pickle=True)\n","\n","processed_validation = [elem for elem in processed_validation if elem != None]\n","\n","val_images = [elem[0] for elem in processed_validation]\n","val_labels = [elem[1] for elem in processed_validation]\n","# val_paths = [elem[2] for elem in processed_validation]\n","\n","processed_validation = None\n","\n","\n","val_images= [center(np.array(elem)).reshape((32, 32,3)) for elem in val_images]\n","val_labels = [int(elem) for elem in val_labels]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Us-aat8vXuEl","colab_type":"code","colab":{}},"source":["# class_names = np.array(['Neutral', 'Happy', 'Sad', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt', None, 'Uncertain', 'No-Face'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHCoI-kq0Lbg","colab_type":"code","colab":{}},"source":["'''Train a simple residual network on the CIFAR10 small images dataset.\n","It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n","(it's still underfitting at that point, though).\n","'''\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D, Add\n","import os\n","from keras.engine.topology import Layer\n","\n","# Define the residual block as a new layer\n","class Residual(Layer):\n","  def __init__(self, channels_in,kernel,**kwargs):\n","      super(Residual, self).__init__(**kwargs)\n","      self.channels_in = channels_in\n","      self.kernel = kernel\n","\n","  def call(self, x):\n","    # the residual block using Keras functional API\n","    first_layer = Activation(\"linear\", trainable=False)(x)\n","    x = Conv2D( self.channels_in, self.kernel, padding=\"same\")(first_layer)\n","    x = Activation(\"relu\")(x)\n","    x = Conv2D( self.channels_in, self.kernel, padding=\"same\")(x)\n","    residual = Add()([x, first_layer])\n","    x = Activation(\"relu\")(residual)\n","    return x\n","\n","  def compute_output_shape(self, input_shape):\n","    return input_shape\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w5OUXO8MebGc","colab_type":"code","colab":{}},"source":["class LayerNormalization(Layer):\n","    def __init__(self, eps=1e-6, **kwargs):\n","        self.eps = eps\n","        super(LayerNormalization, self).__init__(**kwargs)\n","    def build(self, input_shape):\n","        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n","                                     initializer=Ones(), trainable=True)\n","        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n","                                    initializer=Zeros(), trainable=True)\n","        super(LayerNormalization, self).build(input_shape)\n","    def call(self, x):\n","        mean = K.mean(x, axis=-1, keepdims=True)\n","        std = K.std(x, axis=-1, keepdims=True)\n","        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n","    def compute_output_shape(self, input_shape):\n","        return input_shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"da3vPLopfSlQ","colab_type":"code","outputId":"dc0efcec-d49d-4905-d490-fe7f314d7923","executionInfo":{"status":"error","timestamp":1557631361415,"user_tz":420,"elapsed":149439,"user":{"displayName":"Divya Periyakoil","photoUrl":"","userId":"03421379050660572113"}},"colab":{"base_uri":"https://localhost:8080/","height":1031}},"source":["batch_size = 128\n","num_classes = 11\n","epochs = 10\n","data_augmentation = True\n","# num_predictions = 20\n","save_dir = 'root_folder' + 'saved_models'\n","model_name = 'divabella2'\n","\n","# The data, split between train and test sets:\n","# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","\n","x_train = np.array(train_images)\n","y_train = np.array(train_labels)\n","\n","x_test = np.array(val_images)\n","y_test = np.array(val_labels)\n","\n","# train_images = None\n","# train_labels = None\n","# val_images = None\n","# val_labels = None\n","\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","\n","\n","model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n","model.add(Conv2D(32, 3, 3, border_mode='same', input_shape=(32,32,3), activation='relu'))\n","model.add(Conv2D(32, 3, 3, border_mode='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n","model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n","model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n","model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","model.add(Activation('relu'))\n","model.add(Residual(256,(3,3)))\n","model.add(Residual(256,(3,3)))\n","model.add(Residual(256,(3,3)))\n","model.add(Residual(256,(3,3)))\n","model.add(Residual(256,(3,3)))\n","\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","# model.add(BatchNormalization()) #we are adding this in just to see iteration 2\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        validation_data=(x_test, y_test),\n","                        workers=4, steps_per_epoch = 5000)\n","\n","  # Save model and weights\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","model_path = root_folder + 'saved_models/' + model_name\n","model.save(model_path)\n","print('Saved trained model at %s ' % model_path)\n","\n","# Score trained model.\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (93417, 32, 32, 3)\n","93417 train samples\n","5256 test samples\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n"],"name":"stderr"},{"output_type":"stream","text":["Using real-time data augmentation.\n","Epoch 1/10\n","5000/5000 [==============================] - 323s 65ms/step - loss: 1.6319 - acc: 0.4303 - val_loss: 1.9235 - val_acc: 0.3613\n","Epoch 2/10\n","5000/5000 [==============================] - 322s 64ms/step - loss: 1.5774 - acc: 0.4481 - val_loss: 1.9933 - val_acc: 0.3624\n","Epoch 3/10\n","5000/5000 [==============================] - 321s 64ms/step - loss: 1.5319 - acc: 0.4630 - val_loss: 2.0373 - val_acc: 0.3621\n","Epoch 4/10\n","5000/5000 [==============================] - 320s 64ms/step - loss: 1.4873 - acc: 0.4777 - val_loss: 2.0394 - val_acc: 0.3584\n","Epoch 5/10\n","5000/5000 [==============================] - 322s 64ms/step - loss: 1.4462 - acc: 0.4907 - val_loss: 2.1517 - val_acc: 0.3596\n","Epoch 6/10\n","5000/5000 [==============================] - 322s 64ms/step - loss: 1.4044 - acc: 0.5049 - val_loss: 2.1242 - val_acc: 0.3525\n","Epoch 7/10\n","5000/5000 [==============================] - 324s 65ms/step - loss: 1.3651 - acc: 0.5186 - val_loss: 2.2201 - val_acc: 0.3474\n","Epoch 8/10\n","5000/5000 [==============================] - 337s 67ms/step - loss: 1.3276 - acc: 0.5310 - val_loss: 2.2808 - val_acc: 0.3457\n","Epoch 9/10\n","5000/5000 [==============================] - 333s 67ms/step - loss: 1.2918 - acc: 0.5428 - val_loss: 2.3197 - val_acc: 0.3417\n","Epoch 10/10\n","5000/5000 [==============================] - 339s 68ms/step - loss: 1.2567 - acc: 0.5552 - val_loss: 2.4433 - val_acc: 0.3474\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 300\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3556\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"conv2d_1/kernel:0\", shape=(3, 3, 3, 32), dtype=float32_ref) is not an element of this graph.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-679260e8921f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'saved_models/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved trained model at %s '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mlayer_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_weights_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \"\"\"\n\u001b[1;32m   2419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \"\"\"\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \"\"\"\n\u001b[1;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \"\"\"\n\u001b[1;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 307\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    308\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n","\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 3, 32) dtype=float32_ref> cannot be interpreted as a Tensor. (Tensor Tensor(\"conv2d_1/kernel:0\", shape=(3, 3, 3, 32), dtype=float32_ref) is not an element of this graph.)"]}]},{"cell_type":"code","metadata":{"id":"nR2eHA-rgivC","colab_type":"code","colab":{}},"source":["model_path = root_folder + 'saved_models/' + 'best_model'\n","model.save(model_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"keCjQH_bh57W","colab_type":"code","colab":{}},"source":[" # model = Sequential()\n","\n","# model.add(Conv2D(32, 3, 3, border_mode='same', input_shape=(32,32,3), activation='relu'))\n","# model.add(Conv2D(32, 3, 3, border_mode='same', activation='relu'))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n","# model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","# model.add(Conv2D(32, 3, 3, border_mode='same', activation='relu'))\n","\n","# model.add()\n","# model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n","# model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n","# model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# model.add(Flatten())\n","# model.add(Dense(256, activation='relu'))\n","# model.add(Dropout(0.5))\n","\n","# model.add(Dense(256, activation='relu'))\n","# model.add(Dropout(0.5))\n","\n","# model.add(Dense(11))\n","# model.add(Activation('softmax'))\n","    \n","# model.compile(loss='categorical_crossentropy',\n","#             optimizer=RMSprop(lr=0.0001),\n","#             metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8A3hmipVuafi","colab_type":"code","colab":{}},"source":["# model.fit(np.array(train_images), train_labels, epochs=100, batch_size=5000, validation_data=(np.array(val_images),val_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eg0xbYo2AQ-l","colab_type":"code","colab":{}},"source":["# model.predict_classes(np.array(val_images))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JAdVFWYZgnOJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}